{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T16:12:05.706885Z",
          "iopub.status.busy": "2024-04-20T16:12:05.706166Z",
          "iopub.status.idle": "2024-04-20T16:12:05.715690Z",
          "shell.execute_reply": "2024-04-20T16:12:05.713882Z",
          "shell.execute_reply.started": "2024-04-20T16:12:05.706787Z"
        },
        "id": "jzJqC1GO6fxf"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets rouge-score accelerate\n",
        "!pip install sentencepiece\n",
        "!pip install matplotlib\n",
        "!pip install absl-py nltk rouge_score\n",
        "!pip install bert-score\n",
        "!pip install rouge_score\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:05:42.445995Z",
          "iopub.status.busy": "2024-04-26T14:05:42.444803Z",
          "iopub.status.idle": "2024-04-26T14:05:56.366352Z",
          "shell.execute_reply": "2024-04-26T14:05:56.364983Z",
          "shell.execute_reply.started": "2024-04-26T14:05:42.445941Z"
        },
        "id": "nYFe0Fvf5UVr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import gc\n",
        "import time\n",
        "from datetime import datetime\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
        "from datasets import load_dataset, load_metric\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from bert_score import score\n",
        "\n",
        "# Set environment variable for PyTorch CUDA memory allocation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:05:56.370517Z",
          "iopub.status.busy": "2024-04-26T14:05:56.368691Z",
          "iopub.status.idle": "2024-04-26T14:05:56.380736Z",
          "shell.execute_reply": "2024-04-26T14:05:56.378657Z",
          "shell.execute_reply.started": "2024-04-26T14:05:56.370447Z"
        },
        "id": "rSUvWqyB5eu8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class PegasusDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.labels['input_ids'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:05:56.383814Z",
          "iopub.status.busy": "2024-04-26T14:05:56.382443Z",
          "iopub.status.idle": "2024-04-26T14:05:56.396485Z",
          "shell.execute_reply": "2024-04-26T14:05:56.394537Z",
          "shell.execute_reply.started": "2024-04-26T14:05:56.383750Z"
        },
        "id": "3ejCKIe258-x",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def prepare_data(model_name,\n",
        "                 train_texts, train_labels,\n",
        "                 val_texts=None, val_labels=None,\n",
        "                 test_texts=None, test_labels=None):\n",
        "  \"\"\"\n",
        "  Prepare input data for model fine-tuning\n",
        "  \"\"\"\n",
        "  tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "\n",
        "  prepare_val = False if val_texts is None or val_labels is None else True\n",
        "  prepare_test = False if test_texts is None or test_labels is None else True\n",
        "\n",
        "  def tokenize_data(texts, labels):\n",
        "    encodings = tokenizer(texts, truncation=True, padding=True)\n",
        "    decodings = tokenizer(labels, truncation=True, padding=True)\n",
        "    dataset_tokenized = PegasusDataset(encodings, decodings)\n",
        "    return dataset_tokenized\n",
        "\n",
        "  train_dataset = tokenize_data(train_texts, train_labels)\n",
        "  val_dataset = tokenize_data(val_texts, val_labels) if prepare_val else None\n",
        "  test_dataset = tokenize_data(test_texts, test_labels) if prepare_test else None\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:05:56.401246Z",
          "iopub.status.busy": "2024-04-26T14:05:56.400132Z",
          "iopub.status.idle": "2024-04-26T14:05:56.416081Z",
          "shell.execute_reply": "2024-04-26T14:05:56.413845Z",
          "shell.execute_reply.started": "2024-04-26T14:05:56.401190Z"
        },
        "id": "LPwDyKF55ezl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset=None, output_dir='./results'):\n",
        "    \"\"\"\n",
        "    Prepare configurations and base model for fine-tuning\n",
        "    \"\"\"\n",
        "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "    # Freeze all model parameters initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze the last 6 layers of the decoder\n",
        "    num_decoder_layers = model.config.decoder_layers\n",
        "    layers_to_unfreeze = num_decoder_layers - 6\n",
        "    for layer in model.model.decoder.layers[layers_to_unfreeze:]:\n",
        "        for param in layer.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,            # output directory\n",
        "        num_train_epochs=6,               # number of training epochs\n",
        "        per_device_train_batch_size=8,    # batch size per device during training\n",
        "        per_device_eval_batch_size=8,     # batch size for evaluation\n",
        "        save_strategy=\"epoch\",                   # number of updates steps before checkpoint saves\n",
        "        save_total_limit=5,               # limit the total amount of checkpoints\n",
        "        evaluation_strategy='epoch',      # evaluation strategy to adopt during training\n",
        "        eval_steps=100,                   # number of update steps before evaluation\n",
        "        warmup_steps=500,                 # number of warmup steps for learning rate scheduler\n",
        "        weight_decay=0.01,                # strength of weight decay\n",
        "        logging_dir=f'{output_dir}/logs', # directory for storing logs\n",
        "        logging_steps=10,\n",
        "        seed=42 ,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='loss'\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "        args=training_args,                  # training arguments, defined above\n",
        "        train_dataset=train_dataset,         # training dataset\n",
        "        eval_dataset=val_dataset if val_dataset else None,  # evaluation dataset\n",
        "        tokenizer=tokenizer                  # tokenizer for encoding the data\n",
        "    )\n",
        "\n",
        "    return trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-18T08:54:37.609862Z",
          "iopub.status.busy": "2024-04-18T08:54:37.609383Z",
          "iopub.status.idle": "2024-04-18T08:54:45.328930Z",
          "shell.execute_reply": "2024-04-18T08:54:45.317828Z",
          "shell.execute_reply.started": "2024-04-18T08:54:37.609829Z"
        },
        "id": "F3at1nLC5e1-",
        "outputId": "bd8a29bf-1337-442d-c873-95b9a775e28a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syncing run ./results to Weights & Biases (docs)\n",
            "Fine tuning finished successfully\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Load the full XSum dataset\n",
        "    dataset = load_dataset(\"xsum\")\n",
        "\n",
        "    # Sample a subset of the dataset for training, validation, and testing\n",
        "    # Using 20% of training and 50% of validation and testing\n",
        "    train_size = int(0.10 * len(dataset['train']))\n",
        "    val_size = int(0.20 * len(dataset['validation']))\n",
        "    test_size = int(0.20 * len(dataset['test']))\n",
        "\n",
        "    # Randomly shuffle and select the subset for training, validation, and testing\n",
        "    train_dataset = dataset['train'].shuffle(seed=42).select(range(train_size))\n",
        "    val_dataset = dataset['validation'].shuffle(seed=42).select(range(val_size))\n",
        "    test_dataset = dataset['test'].shuffle(seed=42).select(range(test_size))\n",
        "\n",
        "    # Extract texts and labels from the subsets\n",
        "    train_texts, train_labels = train_dataset['document'], train_dataset['summary']\n",
        "    val_texts, val_labels = val_dataset['document'], val_dataset['summary'] if val_dataset else (None, None)\n",
        "    test_texts, test_labels = test_dataset['document'], test_dataset['summary'] if test_dataset else (None, None)\n",
        "\n",
        "    # Prepare data and tokenizer\n",
        "    model_name = 'google/pegasus-large'\n",
        "    train_dataset, val_dataset, test_dataset, tokenizer = prepare_data(\n",
        "        model_name, train_texts, train_labels, val_texts, val_labels, test_texts, test_labels\n",
        "    )\n",
        "      # Prepare the trainer with fine-tuning setup\n",
        "    trainer = prepare_fine_tuning(model_name, tokenizer, train_dataset, val_dataset)\n",
        "    trainer.train()\n",
        "    print(\"Fine tuning finished successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T14:55:41.567320Z",
          "iopub.status.busy": "2024-04-19T14:55:41.566723Z",
          "iopub.status.idle": "2024-04-19T14:56:11.552993Z",
          "shell.execute_reply": "2024-04-19T14:56:11.551834Z",
          "shell.execute_reply.started": "2024-04-19T14:55:41.567276Z"
        },
        "id": "2MU6NFzH5e4K"
      },
      "outputs": [],
      "source": [
        "model_name = \"./results/checkpoint-15306\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-18T10:32:45.257719Z",
          "iopub.status.busy": "2024-04-18T10:32:45.257447Z",
          "iopub.status.idle": "2024-04-18T10:35:14.597171Z",
          "shell.execute_reply": "2024-04-18T10:35:14.596124Z",
          "shell.execute_reply.started": "2024-04-18T10:32:45.257689Z"
        },
        "id": "m2AHdjBH5e6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f1dc3ff-e1d4-45f8-bcee-725f725e7143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading builder script:   100%|          | 2.05k/2.05k \n",
            "Downloading metadata:   100%|          | 954/954 \n",
            "Using custom data configuration default\n",
            "Downloading and preparing dataset xsum/default (download: 245.38 MiB, generated: 507.60 MiB, post-processed: Unknown size, total: 752.98 MiB) to /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934...\n",
            "Downloading data files:   100%|          | 2/2 \n",
            "Downloading data:   100%|          | 255M/255M \n",
            "Downloading data:   100%|          | 1.00/1.00M \n",
            "Generating train split:   100%|          | 204045/204045 \n",
            "Generating validation split:   100%|          | 11332/11332 \n",
            "Generating test split:   100%|          | 11334/11334 \n",
            "Dataset xsum downloaded and prepared to /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934. Subsequent calls will reuse this data.\n",
            "  # 100%|          | 3/3 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"xsum\")\n",
        "test_size = int(0.05 * len(dataset['test']))\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(test_size))\n",
        "test_texts = test_dataset['document']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-18T10:35:14.608256Z",
          "iopub.status.busy": "2024-04-18T10:35:14.607088Z",
          "iopub.status.idle": "2024-04-18T10:41:40.034512Z",
          "shell.execute_reply": "2024-04-18T10:41:40.033380Z",
          "shell.execute_reply.started": "2024-04-18T10:35:14.608220Z"
        },
        "id": "ALlFK8Eq5e8e",
        "outputId": "41e16622-d1da-4237-ed2d-1d0b15bbeb98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 256 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "\n",
        "# Running inference on GPU, if available.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "batch_size = 8\n",
        "generated_summaries = []\n",
        "\n",
        "for i in range(0, test_encodings.input_ids.size(0), batch_size):\n",
        "    batch_input_ids = test_encodings.input_ids[i:i+batch_size].to(device)\n",
        "    summary_ids = model.generate(batch_input_ids)\n",
        "    generated_summaries += [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-18T10:46:14.740648Z",
          "iopub.status.busy": "2024-04-18T10:46:14.740187Z",
          "iopub.status.idle": "2024-04-18T10:46:23.668809Z",
          "shell.execute_reply": "2024-04-18T10:46:23.667325Z",
          "shell.execute_reply.started": "2024-04-18T10:46:14.740613Z"
        },
        "id": "PO1-LfMZ5e-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e9d181-9b89-487f-bd2f-8d4d1fb69775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1 0.3538725498074857\n",
            "rouge2 0.14308078644601482\n",
            "rougeL 0.2797705677040414\n",
            "rougeLsum 0.2802197843314166\n"
          ]
        }
      ],
      "source": [
        "rouge = load_metric('rouge')\n",
        "references = test_dataset['summary']\n",
        "results = rouge.compute(predictions=generated_summaries, references=references, use_stemmer=True)\n",
        "\n",
        "# Print out the results\n",
        "for key in results.keys():\n",
        "    print(key, results[key].mid.fmeasure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-19T14:56:39.099940Z",
          "iopub.status.busy": "2024-04-19T14:56:39.099005Z",
          "iopub.status.idle": "2024-04-19T14:57:15.652758Z",
          "shell.execute_reply": "2024-04-19T14:57:15.652117Z",
          "shell.execute_reply.started": "2024-04-19T14:56:39.099887Z"
        },
        "id": "ZFZFSLm55fAr",
        "outputId": "1a8267a4-44bd-435d-f445-2745592d766f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dogs can understand that certain words refer to specific objects, according to a recent study, suggesting that they may understand words in a similar way to humans.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-15306\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "Dogs can understand that certain words refer to specific objects, according to a recent study, suggesting that they may understand words in a similar way to humans.\n",
        "\n",
        "It offers the first evidence of brain activity for this comprehension in a non-human animal, researchers said, though the studyâ€™s conclusion has faced scrutiny from other experts in the field.\n",
        "\n",
        " It has long been known that dogs can learn commands like sit, stay, or fetch and can respond to these words with learned behaviors, often with the help of a treat or two, but untangling their understanding of nouns has proven more difficult.\n",
        " \"\"\"\n",
        "\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T17:16:14.365780Z",
          "iopub.status.busy": "2024-04-20T17:16:14.365203Z",
          "iopub.status.idle": "2024-04-20T17:16:30.877809Z",
          "shell.execute_reply": "2024-04-20T17:16:30.876440Z",
          "shell.execute_reply.started": "2024-04-20T17:16:14.365734Z"
        },
        "tags": [],
        "id": "960id3PKUd-s"
      },
      "outputs": [],
      "source": [
        "# Path to the saved checkpoint\n",
        "checkpoint_path = \"./results/checkpoint-10204\"\n",
        "\n",
        "# Load the model and tokenizer from the checkpoint\n",
        "model = PegasusForConditionalGeneration.from_pretrained(checkpoint_path)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T17:16:30.880498Z",
          "iopub.status.busy": "2024-04-20T17:16:30.880093Z",
          "iopub.status.idle": "2024-04-20T17:19:56.019520Z",
          "shell.execute_reply": "2024-04-20T17:19:56.018225Z",
          "shell.execute_reply.started": "2024-04-20T17:16:30.880466Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlyfcZbWUd-s",
        "outputId": "e341dd55-55e8-4c09-c473-edc996fc3616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading builder script:   100%|          | 2.05k/2.05k \n",
            "Downloading metadata:   100%|          | 954/954 \n",
            "Using custom data configuration default\n",
            "Downloading and preparing dataset xsum/default (download: 245.38 MiB, generated: 507.60 MiB, post-processed: Unknown size, total: 752.98 MiB) to /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934...\n",
            "Downloading data files:   100%|          | 2/2 \n",
            "Downloading data:   100%|          | 255/255M \n",
            "Downloading data:   100%|          | 1.00/1.00M \n",
            "Generating train split:   100%|          | 204045/204045 \n",
            "Generating validation split:   100%|          | 11332/11332 \n",
            "Generating test split:   100%|          | 11332/11334 \n",
            "Dataset xsum downloaded and prepared to /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934. Subsequent calls will reuse this data.\n",
            "  100%|          | 3/3 \n",
            "Downloading spiece.model:   100%|          | 1.82/1.82M \n",
            "Downloading special_tokens_map.json:   100%|          | 65.0/65.0 \n",
            "Downloading tokenizer_config.json:   100%|          | 88.0/88.0 \n",
            "Downloading config.json:   100%|          | 3.02k/3.02k \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"xsum\")\n",
        "\n",
        "# Sample a subset of the dataset for training, validation, and testing\n",
        "    # Using 10% of training and 20% of validation and testing\n",
        "train_size = int(0.10 * len(dataset['train']))\n",
        "val_size = int(0.20 * len(dataset['validation']))\n",
        "test_size = int(0.20 * len(dataset['test']))\n",
        "\n",
        "    # Randomly shuffle and select the subset for training, validation, and testing\n",
        "train_dataset = dataset['train'].shuffle(seed=42).select(range(train_size))\n",
        "val_dataset = dataset['validation'].shuffle(seed=42).select(range(val_size))\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(test_size))\n",
        "\n",
        "train_texts, train_labels = train_dataset['document'], train_dataset['summary']\n",
        "val_texts, val_labels = val_dataset['document'], val_dataset['summary'] if val_dataset else (None, None)\n",
        "test_texts, test_labels = test_dataset['document'], test_dataset['summary'] if test_dataset else (None, None)\n",
        "\n",
        "# Tokenize the data\n",
        "train_dataset, val_dataset, _, _ = prepare_data(\n",
        "    'google/pegasus-large', train_texts, train_labels, val_texts, val_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T17:19:56.021674Z",
          "iopub.status.busy": "2024-04-20T17:19:56.020925Z",
          "iopub.status.idle": "2024-04-20T17:19:56.070163Z",
          "shell.execute_reply": "2024-04-20T17:19:56.069252Z",
          "shell.execute_reply.started": "2024-04-20T17:19:56.021640Z"
        },
        "tags": [],
        "id": "O_YYken8Ud-s"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Unfreeze the last 6 layers of the decoder\n",
        "num_decoder_layers = model.config.decoder_layers\n",
        "layers_to_unfreeze = num_decoder_layers - 6\n",
        "for layer in model.model.decoder.layers[layers_to_unfreeze:]:\n",
        "    for param in layer.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",         # Directory to save the outputs\n",
        "    num_train_epochs=10,            # Total epochs to reach including previous training\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_dir=\"./results/logs\",   # Directory to save logs\n",
        "    resume_from_checkpoint=checkpoint_path,  # Continue from last checkpoint\n",
        "    seed=42,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='loss'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-20T17:19:56.072551Z",
          "iopub.status.busy": "2024-04-20T17:19:56.072013Z"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JRuhDZoUd-s",
        "outputId": "f7bca9aa-d4e6-4e83-ec8b-904fa186b790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syncing run ./results to Weights & Biases (docs)\n",
            "Fine tuning finished successfully\n"
          ]
        }
      ],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Resume training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T19:02:15.797678Z",
          "iopub.status.busy": "2024-04-21T19:02:15.797298Z",
          "iopub.status.idle": "2024-04-21T19:02:27.262932Z",
          "shell.execute_reply": "2024-04-21T19:02:27.262038Z",
          "shell.execute_reply.started": "2024-04-21T19:02:15.797653Z"
        },
        "id": "orhdTAS2Ud-s"
      },
      "outputs": [],
      "source": [
        "model_name = \"./results/checkpoint-10204\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T19:15:26.695723Z",
          "iopub.status.busy": "2024-04-21T19:15:26.695359Z",
          "iopub.status.idle": "2024-04-21T19:15:27.077796Z",
          "shell.execute_reply": "2024-04-21T19:15:27.077138Z",
          "shell.execute_reply.started": "2024-04-21T19:15:26.695690Z"
        },
        "id": "RZKgsst7Ud-t"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"xsum\")\n",
        "test_size = int(0.05 * len(dataset['test']))\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(test_size))\n",
        "test_texts = test_dataset['document']\n",
        "test_references = test_dataset['summary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T19:02:27.607297Z",
          "iopub.status.busy": "2024-04-21T19:02:27.607016Z",
          "iopub.status.idle": "2024-04-21T19:05:47.044179Z",
          "shell.execute_reply": "2024-04-21T19:05:47.042886Z",
          "shell.execute_reply.started": "2024-04-21T19:02:27.607297Z"
        },
        "id": "g3uWgPD7Ud-t"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "batch_size = 8\n",
        "generated_summaries = []\n",
        "\n",
        "for i in range(0, test_encodings.input_ids.size(0), batch_size):\n",
        "    batch_input_ids = test_encodings.input_ids[i:i+batch_size].to(device)\n",
        "    summary_ids = model.generate(batch_input_ids)\n",
        "    generated_summaries += [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T19:05:47.046299Z",
          "iopub.status.busy": "2024-04-21T19:05:47.045989Z",
          "iopub.status.idle": "2024-04-21T19:05:51.782297Z",
          "shell.execute_reply": "2024-04-21T19:05:51.781207Z",
          "shell.execute_reply.started": "2024-04-21T19:05:47.046299Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ZGD5RKUd-t",
        "outputId": "b9aa758c-d497-4a7b-e8f1-94e4fc6a8839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1 0.3658887282212533\n",
            "rouge2 0.1500332057209846\n",
            "rougeL 0.29663345261467633\n",
            "rougeLsum 0.29602682013087056\n"
          ]
        }
      ],
      "source": [
        "rouge = load_metric('rouge')\n",
        "references = test_dataset['summary']\n",
        "results = rouge.compute(predictions=generated_summaries, references=references, use_stemmer=True)\n",
        "\n",
        "# Print out the results\n",
        "for key in results.keys():\n",
        "    print(key, results[key].mid.fmeasure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T19:16:52.712065Z",
          "iopub.status.busy": "2024-04-21T19:16:52.711700Z",
          "iopub.status.idle": "2024-04-21T19:17:42.660385Z",
          "shell.execute_reply": "2024-04-21T19:17:42.659585Z",
          "shell.execute_reply.started": "2024-04-21T19:16:52.712038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_JGX0nKUd-t",
        "outputId": "8ea8ad58-ce44-49ef-f7ee-b8e6897c8d1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore Precision (mean): 0.4256\n",
            "BERTScore Recall (mean): 0.3770\n",
            "BERTScore F1 (mean): 0.4014\n"
          ]
        }
      ],
      "source": [
        "# Calculate BERTScore\n",
        "P, R, F1 = score(generated_summaries, test_references, lang=\"en\", rescale_with_baseline=True)\n",
        "\n",
        "# Calculate the mean scores for BERTScore\n",
        "P_mean = P.mean().item()\n",
        "R_mean = R.mean().item()\n",
        "F1_mean = F1.mean().item()\n",
        "\n",
        "# Print the BERTScore results\n",
        "print(f\"BERTScore Precision (mean): {P_mean:.4f}\")\n",
        "print(f\"BERTScore Recall (mean): {R_mean:.4f}\")\n",
        "print(f\"BERTScore F1 (mean): {F1_mean:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T18:50:11.088266Z",
          "iopub.status.idle": "2024-04-21T18:50:11.088546Z",
          "shell.execute_reply": "2024-04-21T18:50:11.088420Z",
          "shell.execute_reply.started": "2024-04-21T18:50:11.088406Z"
        },
        "id": "uwFV-4gtUd-t"
      },
      "outputs": [],
      "source": [
        "model_name = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-21T18:50:11.091971Z",
          "iopub.status.idle": "2024-04-21T18:53:02.068448Z",
          "shell.execute_reply": "2024-04-21T18:53:02.067393Z",
          "shell.execute_reply.started": "2024-04-21T18:51:39.394038Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9noEIdmLUd-t",
        "outputId": "1302ef3b-a4e2-42a5-e81a-bb70a98c2151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using custom data configuration default\n",
            "Downloading and preparing dataset xsum/default (download: 245.38 MiB, generated: 507.60 MiB, post-processed: Unknown size, total: 752.98 MiB) to /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934...\n",
            "Downloading data files:   100%|          | 2/2 \n",
            "Generating train split:   100%|          | 204045/204045 \n",
            "Generating validation split:   100%|          | 11332/11332 \n",
            "Generating test split:   100%|          | 11334/11334 \n",
            "Dataset xsum downloaded and prepared to /root/.cache/huggingface/datasets/xsum/default/1.2.0/32c23220eadddb1149b16ed2e9430a05293768cfffbdfd151058697d4c11f934. Subsequent calls will reuse this data.\n",
            "  100%|          | 3/3 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"xsum\")\n",
        "test_size = int(0.05 * len(dataset['test']))\n",
        "test_dataset = dataset['test'].shuffle(seed=42).select(range(test_size))\n",
        "test_texts = test_dataset['document']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:02.070503Z",
          "iopub.status.busy": "2024-04-21T18:53:02.069750Z",
          "iopub.status.idle": "2024-04-21T18:56:24.322361Z",
          "shell.execute_reply": "2024-04-21T18:56:24.321462Z",
          "shell.execute_reply.started": "2024-04-21T18:53:02.070477Z"
        },
        "id": "sAp7F6MtUd-t",
        "outputId": "a7799504-1531-457c-face-71838073211f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 256 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "test_encodings = tokenizer(test_texts, truncation=True, padding='longest', return_tensors=\"pt\")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "batch_size = 8\n",
        "generated_summaries = []\n",
        "\n",
        "for i in range(0, test_encodings.input_ids.size(0), batch_size):\n",
        "    batch_input_ids = test_encodings.input_ids[i:i+batch_size].to(device)\n",
        "    summary_ids = model.generate(batch_input_ids)\n",
        "    generated_summaries += [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:56:24.325076Z",
          "iopub.status.busy": "2024-04-21T18:56:24.324396Z",
          "iopub.status.idle": "2024-04-21T18:56:31.214316Z",
          "shell.execute_reply": "2024-04-21T18:56:31.213252Z",
          "shell.execute_reply.started": "2024-04-21T18:56:24.325051Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYGLN6QHUd-t",
        "outputId": "fbb832c6-8e05-4a98-b659-da72cd02df8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1 0.3615360871166696\n",
            "rouge2 0.14448061052666816\n",
            "rougeL 0.28897143776885015\n",
            "rougeLsum 0.28845520980130684\n"
          ]
        }
      ],
      "source": [
        "rouge = load_metric('rouge')\n",
        "references = test_dataset['summary']\n",
        "results = rouge.compute(predictions=generated_summaries, references=references, use_stemmer=True)\n",
        "\n",
        "# Print out the results\n",
        "for key in results.keys():\n",
        "    print(key, results[key].mid.fmeasure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:56:31.218866Z",
          "iopub.status.busy": "2024-04-21T18:56:31.218480Z",
          "iopub.status.idle": "2024-04-21T18:56:50.931251Z",
          "shell.execute_reply": "2024-04-21T18:56:50.930625Z",
          "shell.execute_reply.started": "2024-04-21T18:56:31.218809Z"
        },
        "id": "NAhVrF79Ud-t",
        "outputId": "4757b62f-1899-40f8-a4f6-3b895dda9557"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dogs have been shown to be able to understand certain words, according to a new study in the field of animal psychology.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "Dogs can understand that certain words refer to specific objects, according to a recent study, suggesting that they may understand words in a similar way to humans.\n",
        "\n",
        "It offers the first evidence of brain activity for this comprehension in a non-human animal, researchers said, though the studyâ€™s conclusion has faced scrutiny from other experts in the field.\n",
        "\n",
        " It has long been known that dogs can learn commands like sit, stay, or fetch and can respond to these words with learned behaviors, often with the help of a treat or two, but untangling their understanding of nouns has proven more difficult.\n",
        " \"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:11:38.476846Z",
          "iopub.status.busy": "2024-04-26T14:11:38.476296Z",
          "iopub.status.idle": "2024-04-26T14:12:27.493478Z",
          "shell.execute_reply": "2024-04-26T14:12:27.491958Z",
          "shell.execute_reply.started": "2024-04-26T14:11:38.476805Z"
        },
        "id": "QHoPVdl4Ud-u",
        "outputId": "494d67f2-7348-4b5e-8cbb-efeefd94231f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google has released a new version of its smartwatch, the G4SKY.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "GizmoChina has spotted data about Google's smartwatch has been spotted in the US Federal Communications Commission's (FCC) certification website's database. The source believes it to be the Pixel Watch 2a, the budget flagship version of the Pixel Watch 2.\n",
        "\n",
        "The FCC has tagged Google's new watch with the catalog number G4SKY and the device is believed to run on WearOS. It will also get Bluetooth, Wi-Fi and LTE support in one model.\n",
        "\n",
        "In addition, the FCC has information about a UWB module that can be used to locate the watch if it is lost and unlock a synced smartphone more accurately.\n",
        " \"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:19:36.479154Z",
          "iopub.status.busy": "2024-04-26T14:19:36.478575Z",
          "iopub.status.idle": "2024-04-26T14:19:58.891887Z",
          "shell.execute_reply": "2024-04-26T14:19:58.890202Z",
          "shell.execute_reply.started": "2024-04-26T14:19:36.479113Z"
        },
        "id": "Q3JOGun8Ud-u",
        "outputId": "9cbc01f1-da71-47cc-f09f-479982b52e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three of the brightest solar flares on the Sun's surface are caused by sunspots and the other by solar wind.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "Four almost simultaneous flares erupted from the Sun yesterday, which is considered a very rare phenomenon. As a result of the explosions, emissions can reach the Earth, causing a geomagnetic storm, reports Space.com.\n",
        "\n",
        "Solar flares are explosions on the Sun's surface that release intense bursts of electromagnetic radiation. They occur when magnetic energy builds up in the Sun's atmosphere and is quickly released from it.\n",
        "\n",
        "Three of the flares were caused by sunspots and the other by magnetic filaments hundreds of thousands of miles apart and connected by nearly invisible magnetic rings in the Sun's outer atmosphere known as the corona.\n",
        "\"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:21:10.870762Z",
          "iopub.status.busy": "2024-04-26T14:21:10.869450Z",
          "iopub.status.idle": "2024-04-26T14:21:54.934030Z",
          "shell.execute_reply": "2024-04-26T14:21:54.932370Z",
          "shell.execute_reply.started": "2024-04-26T14:21:10.870701Z"
        },
        "id": "1IbAI6IvUd-u",
        "outputId": "df0bb72e-a13d-4fa4-b755-bb0dc1408fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Universe has been expanding ever since the Big Bang theory was first proposed in 1859.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "The current understanding of the origin of the Universe is based on the Big Bang theory, which is supported by a huge amount of observational data. According to this theory, the universe began approximately 13.8 billion years ago: all matter, energy, space and time were concentrated at one point, known as a singularity. The Universe then underwent a rapid and violent expansion known as the Big Bang, during which space itself began to expand and cool.\n",
        "\"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:22:06.755354Z",
          "iopub.status.busy": "2024-04-26T14:22:06.754786Z",
          "iopub.status.idle": "2024-04-26T14:22:38.884435Z",
          "shell.execute_reply": "2024-04-26T14:22:38.882911Z",
          "shell.execute_reply.started": "2024-04-26T14:22:06.755313Z"
        },
        "id": "V-pjBZNhUd-u",
        "outputId": "c125f912-e84c-4d04-9abd-688a6149a28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of attacks on Android devices in Russia has more than doubled in the past year, according to a report by Kaspersky Lab.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "In the first quarter of 2024, the number of attacks on Android smartphone users in Russia increased 5.2 times compared to the same period last year. According to cybersecurity expert Dmitry Kalinin, more than 19 million Russian users became victims of hackers during the specified period.\n",
        "\n",
        "Among the most dangerous threats were the Dwphon and Mamont viruses. Dwphon is capable of collecting personal data of the device owner, information about applications, and even downloading malicious software without the user's consent.\n",
        "\n",
        "Mamont is aimed at extorting payment data and access to SMS on an infected device.\n",
        "\n",
        "Some of the malware, including Dwphon, may come pre-installed on devices right out of the box. As Kalinin noted, this poses a serious threat to users, since attackers can compromise the device supply chain by introducing malware in the early stages of production without the knowledge of the manufacturer or other participants in this process.\n",
        "Three of the flares were caused by sunspots and the other by magnetic filaments hundreds of thousands of miles apart and connected by nearly invisible magnetic rings in the Sun's outer atmosphere known as the corona.\n",
        "\"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:43:40.357548Z",
          "iopub.status.busy": "2024-04-26T14:43:40.357164Z",
          "iopub.status.idle": "2024-04-26T14:44:39.940183Z",
          "shell.execute_reply": "2024-04-26T14:44:39.938208Z",
          "shell.execute_reply.started": "2024-04-26T14:43:40.357512Z"
        },
        "id": "zhqS_2NrUd-u",
        "outputId": "74c63df6-7798-4057-b2b5-1d08cc9930d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parents should not lose the moment and explain to a child that he is already too close to the dangerous point, says an expert.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "Computer games for children should not replace the whole world around them. Nikita Kocherzhenko, CEO of Uncom OS, a company that develops operating systems, told kp.ru how parents can understand that a child is becoming addicted to computer games and what needs to be done.\n",
        "\n",
        "According to him, when obsession with games turns into addiction, the child's real problems and needs begin to be pushed into the background.\n",
        "\n",
        "\"For the sake of playing, the child begins to sacrifice his studies or simply forgets to eat. If going out of the game causes aggression, it gives reason to think,\" he said.\n",
        "\n",
        "Nikita Kocherzhenko noted that if failures in the game cause aggression in the child, and it does not disappear even after turning off the game, this is also a very alarming signal.\n",
        "\n",
        "\"If the game is the only interest, and it is not possible to distract the child with something else, then that same cheap dopamine begins to subordinate itself to the child. And parents should not lose the moment and explain to the child that he is already too close to the dangerous point. It is necessary to stop,\" said the expert.\n",
        "\n",
        "At the same time, he noted that computer games can also become an opportunity for a child's development and a source of new experience that cannot be obtained elsewhere.\n",
        "\n",
        "Researchers at the University of York have found that puzzles and strategy games improve a child's memory and concentration.\n",
        "\"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T14:46:38.874734Z",
          "iopub.status.busy": "2024-04-26T14:46:38.872907Z",
          "iopub.status.idle": "2024-04-26T14:47:31.406357Z",
          "shell.execute_reply": "2024-04-26T14:47:31.404163Z",
          "shell.execute_reply.started": "2024-04-26T14:46:38.874666Z"
        },
        "id": "RShRfZEfUd-u",
        "outputId": "54ff9e22-d6d1-472d-f026-5087b9d614df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scientists have found that 10 per cent of people with multiple sclerosis have high levels of antibodies that can attack the body, a finding they hope will help them diagnose the disease.\n"
          ]
        }
      ],
      "source": [
        "path_to_checkpoint = \"./results/checkpoint-12755\"\n",
        "model = PegasusForConditionalGeneration.from_pretrained(path_to_checkpoint)\n",
        "tokenizer = PegasusTokenizer.from_pretrained(path_to_checkpoint)\n",
        "\n",
        "original_text = \"\"\"\n",
        "An autoimmune disease such as multiple sclerosis is thought to result in part from rare immune responses to common infections.\n",
        "\n",
        "For this study, scientists analysed blood samples taken from 250 multiple sclerosis patients before and after diagnosis and compared them with blood samples from healthy people.\n",
        "\n",
        "The researchers thought they would see a spike in antibody levels when multiple sclerosis patients showed the first symptoms of the disease.\n",
        "\n",
        "\n",
        "The researchers thought they would see a spike in antibody levels when multiple sclerosis patients showed the first symptoms of the disease. Instead, they found that 10 per cent of multiple sclerosis patients had strikingly high levels of autoantibodies - antibodies that can attack the body itself - years before diagnosis.\n",
        "\n",
        "About a dozen of the autoantibodies identified by the researchers had chemical compositions similar to those found in common viruses. These included the Epstein-Barr virus, which affects more than 85 per cent of all people and has been highlighted in earlier studies as a potential cause of multiple sclerosis.\n",
        "\n",
        "In fact, these 10% of multiple sclerosis patients showed signs of an immune war raging in the brain years before diagnosis. These patients also had elevated levels of a protein that is released when neurons are destroyed.\n",
        "\n",
        "To confirm their findings, the researchers analysed blood samples from patients participating in another study linked to neurological symptoms. Again, the same set of autoantibodies were detected in 10 per cent of patients diagnosed with multiple sclerosis.\n",
        "\n",
        "Scientists hope that these antibodies will someday form the basis of a simple blood test to detect forms of multiple sclerosis.\n",
        "\"\"\"\n",
        "\n",
        "# Encode the text into tensor and run it through the model\n",
        "inputs = tokenizer(original_text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, length_penalty=2.0, early_stopping=True)\n",
        "\n",
        "# Decode and print the summary\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "print(summary)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}